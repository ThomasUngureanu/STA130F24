{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21f942af",
   "metadata": {},
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "795dc8c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a53b55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id       1\n",
      "song    11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Check for missing values in each column\n",
    "missing_values = df.isna().sum()\n",
    "\n",
    "# Display columns with missing values\n",
    "print(missing_values[missing_values > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc62852",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b099785",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the dataset (rows, columns)\n",
    "data_shape = data.shape\n",
    "data_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcbd58c",
   "metadata": {},
   "source": [
    "Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5a954ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_n', 'id', 'name', 'gender', 'species', 'birthday', 'personality',\n",
       "       'song', 'phrase', 'full_id', 'url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Get the names of the columns in the dataset\n",
    "data_columns_summary = data.columns\n",
    "data_columns_summary \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad123fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n",
      "personality\n",
      "lazy      60\n",
      "normal    59\n",
      "cranky    55\n",
      "snooty    55\n",
      "jock      55\n",
      "peppy     49\n",
      "smug      34\n",
      "uchi      24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Summary statistics for numerical columns\n",
    "summary_stats = data.describe()\n",
    "\n",
    "# Display the result\n",
    "print(summary_stats)\n",
    "\n",
    "# Count of unique values in the 'personality' column\n",
    "personality_counts = data['personality'].value_counts()\n",
    "\n",
    "# Display the result\n",
    "print(personality_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f318b4f2",
   "metadata": {},
   "source": [
    "This will output summary statistics for numerical columns, such as mean, std (standard deviation), min, max, and percentiles (25%, 50%, 75%) and will show the count of villagers for each personality type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871b6685",
   "metadata": {},
   "source": [
    "Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c8ac707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891, 15)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Summary statistics for numerical columns\n",
    "summary_stats = data.describe()\n",
    "# Display the result\n",
    "print(summary_stats)\n",
    "\n",
    "\n",
    "# Get the shape of the dataset (rows, columns)\n",
    "data_shape = data.shape\n",
    "data_shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a5fb17",
   "metadata": {},
   "source": [
    "Using the alternate dataset, we can observe that data.describe() did not count the empty rows in the age column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82851875",
   "metadata": {},
   "source": [
    "Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce8316f",
   "metadata": {},
   "source": [
    "Attributes are the characteristics of an object. They store a certain type of information about the object within the code and can be accessed without parentheses. the purpose of Attributes is they simply give information that is held and provided in the code.\n",
    "\n",
    "Methods are functions that are unique to the object it is given with and they can perform actions and calculations on a object.\n",
    "they are called with parentheses with the ability to pass arguments within the parentheses. Methods perform a task or gives a result for the object.\n",
    "\n",
    "The key difference between a attribute and a method is that attributes are variables that provide information while Methods are functions that perform actions or computations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46230001",
   "metadata": {},
   "source": [
    "Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1357eb",
   "metadata": {},
   "source": [
    "Count: The number of non-missing values in each column.\n",
    "\n",
    "Mean: The average value for the column. It is calculated by summing all the values and dividing by the count.\n",
    "\n",
    "Standard deviation (std): A measure of how speed out the values are from the mean. \n",
    "\n",
    "Minimum (min): The smallest value in the column\n",
    "\n",
    "25th percentile (25%): known as the first quartile, it is the value below which 25% of the data is.\n",
    "\n",
    "50th percentile (50%): The median, the middle value of the data when it is sorted.\n",
    "\n",
    "75th percentile (75%): known as the third quartile. it is the value below which 75% of the data is.\n",
    "\n",
    "Maximum (max): the largest value in the column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f388c5",
   "metadata": {},
   "source": [
    "Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bc24f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   row_n       id     name  gender    species personality         song  \\\n",
      "0      2  admiral  Admiral    male       bird      cranky   Steep Hill   \n",
      "1      3  agent-s  Agent S  female   squirrel       peppy      DJ K.K.   \n",
      "2      4    agnes    Agnes  female        pig        uchi   K.K. House   \n",
      "3      6       al       Al    male    gorilla        lazy   Steep Hill   \n",
      "4      7  alfonso  Alfonso    male  alligator        lazy  Forest Life   \n",
      "\n",
      "     phrase           full_id  \\\n",
      "0   aye aye  villager-admiral   \n",
      "1  sidekick  villager-agent-s   \n",
      "2   snuffle    villager-agnes   \n",
      "3   Ayyeeee       villager-al   \n",
      "4  it'sa me  villager-alfonso   \n",
      "\n",
      "                                                 url  \n",
      "0  https://villagerdb.com/images/villagers/thumb/...  \n",
      "1  https://villagerdb.com/images/villagers/thumb/...  \n",
      "2  https://villagerdb.com/images/villagers/thumb/...  \n",
      "3  https://villagerdb.com/images/villagers/thumb/...  \n",
      "4  https://villagerdb.com/images/villagers/thumb/...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Delete irrelevant columns like 'birthday'\n",
    "del df['birthday']\n",
    "\n",
    "# Drop rows where 'name', 'species', or 'personality' have missing values\n",
    "df_cleaned = df.dropna(subset=['name', 'species', 'personality'])\n",
    "\n",
    "# Display the cleaned dataset\n",
    "print(df_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca3ade",
   "metadata": {},
   "source": [
    "Part 1: Shown in code above\n",
    "\n",
    "Part 2: Shown in code above\n",
    "\n",
    "Part 3: Applying del df['birthday'] before df.dropna(subset=['name', 'species', 'personality']) results in only the relevant columns in the data set being considered, making handing missing data easier and can prevent any unnecessary data loss, leading to the data cleaning process becoming more efficient.\n",
    "\n",
    "Part 4: Shown in code above\n",
    "\n",
    "Before report:\n",
    "\n",
    "Use df.dropna() to manage missing values dynamically and retain as much data as possible.\n",
    "Use del to explicitly remove columns that are deemed unnecessary or overly incomplete.\n",
    "\n",
    "After report:\n",
    "\n",
    "Delete irrelevant columns like 'birthday' and drop rows where 'name', 'species', or 'personality' have missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd6b7e9",
   "metadata": {},
   "source": [
    "Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f40b59b",
   "metadata": {},
   "source": [
    "Part 1:\n",
    "\n",
    "df.groupby(\"col1\"): This groups the data in the DataFrame df by the unique values in column col1.\n",
    "\n",
    "[\"col2\"]: This selects the column col2 from the grouped data, which will be the focus of the aggregation or summary.\n",
    "\n",
    ".describe(): This generates summary statistics (like count, mean, std, min, 25%, 50%, 75%, max) for the numerical data in col2 for each group created by col1.\n",
    "\n",
    "df.groupby(\"col1\")[\"col2\"].describe() groups the data by col1 and provides summary statistics for col2 for each group. This is useful for understanding how a numerical column (like age) behaves across different categories (like species)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d411a1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          count unique       top freq\n",
      "species                              \n",
      "alligator     7      7   Alfonso    1\n",
      "anteater      7      7  Anabelle    1\n",
      "bear         15     15    Beardo    1\n",
      "bird         13     13   Admiral    1\n",
      "bull          6      6     Angus    1\n",
      "cat          23     23     Ankha    1\n",
      "chicken       9      9       Ava    1\n",
      "cow           4      4     Naomi    1\n",
      "cub          16     16    Barold    1\n",
      "deer         10     10       Bam    1\n",
      "dog          16     16       Bea    1\n",
      "duck         17     17      Bill    1\n",
      "eagle         9      9    Amelia    1\n",
      "elephant     11     11      Axel    1\n",
      "frog         18     18  Camofrog    1\n",
      "goat          8      8     Billy    1\n",
      "gorilla       9      9        Al    1\n",
      "hamster       8      8     Apple    1\n",
      "hippo         7      7    Bertha    1\n",
      "horse        15     15  Annalise    1\n",
      "kangaroo      8      8    Astrid    1\n",
      "koala         9      9     Alice    1\n",
      "lion          7      7       Bud    1\n",
      "monkey        8      8      Deli    1\n",
      "mouse        15     15  Anicotti    1\n",
      "octopus       3      3    Marina    1\n",
      "ostrich      10     10   Blanche    1\n",
      "penguin      13     13    Aurora    1\n",
      "pig          15     15     Agnes    1\n",
      "rabbit       20     20    Bonbon    1\n",
      "rhino         6      6   Hornsby    1\n",
      "sheep        13     13   Baabara    1\n",
      "squirrel     18     18   Agent S    1\n",
      "tiger         7      7    Bangle    1\n",
      "wolf         11     11     Audie    1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Group by 'species' and describe 'name'\n",
    "grouped_summary = data.groupby('species')['name'].describe()\n",
    "\n",
    "# Display the grouped summary\n",
    "print(grouped_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d81fca",
   "metadata": {},
   "source": [
    "Part 2: \n",
    "\n",
    "The reason for being fundamentally different is  df.describe() gives you a higher level of overview for the dataset's columns (globally) while df.groupby(\"col1\")[\"col2\"].describe() breaks down the dataset in groups, providing some insight on the subset of the data. This shows the patterns and statistics within each group (such as how many villagers are of a certain species) instead of looking at the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb837b",
   "metadata": {},
   "source": [
    " Part 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b52928",
   "metadata": {},
   "source": [
    "Part A. \n",
    "\n",
    "\n",
    "For this part, the chatbot was much more helpful in fixing the error in my code. It gave me a short but detailed explanation on how to add the import part of the code and gave me some key points in what each part of the import code means, such as pd being an alias. When searching for help on google, the solution that was provided was good, but not as detailed and helpful as ChatGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4e7e7f",
   "metadata": {},
   "source": [
    "Part B. \n",
    "\n",
    "\n",
    "For this part, ChatGPT simply told me that my titanics.csv is a typo and titanic.csv is the correct url. Google gave me alot more information that I didnt need, making it more confusing for me to naviagate through. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a7e19a",
   "metadata": {},
   "source": [
    "Part C.\n",
    "\n",
    "\n",
    "ChatGPT auto corrected the coding mistake, changing the variable to what is was suppose to be and then telling me what it does. Google gave me the correct answer with some examples but didnt use my dataset. ChatGPT was more useful for acting like the mistake didnt exist, but google shows a more detailed way to write the code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3969d588",
   "metadata": {},
   "source": [
    "Part D.\n",
    "\n",
    "\n",
    "ChatGPT told me the problem right away and gave me the correct answer to fix it. Google gave me examples again but was not specific, therefore ChatGPT was the better alternative. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db767db",
   "metadata": {},
   "source": [
    "Part E. \n",
    "\n",
    "\n",
    "ChatGPT told the mistake right away, changing the code I gave it and giving me the correct code to use. Google did the same thing as in Part D and gave me examples not relating to my data with a tip to pay attention to spelling. ChatGPT got to the point quicker and did what google did but better.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0979079",
   "metadata": {},
   "source": [
    "Part F. \n",
    "\n",
    "\n",
    "ChatGPT did the same thing it did in part C where it auto corrected the line of code and gave me the correct answer with no mention of an error. Google also did the same thing, giving me examples that weren't direct, but indicated that I did have an error. Google was better to understand my mistake and fixing it while ChatGPT just gave the answer without explaining the problem.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be3f15",
   "metadata": {},
   "source": [
    "Part G.\n",
    "\n",
    "\n",
    "ChatGPT detected an error in the titanic_df.groupby(\"sex\")[age].describe() code and was able to point out the missing quotes around age. Google didnt help me directly and provided some examples. ChatGPT was more clear and simple compaired to google.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f1d51",
   "metadata": {},
   "source": [
    "Question 9\n",
    "\n",
    "\n",
    "Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d053c5",
   "metadata": {},
   "source": [
    "Summary\n",
    "\n",
    "https://chatgpt.com/c/66e0c270-1e50-800b-ab53-17fcc89b8595\n",
    "https://chatgpt.com/c/66e37eed-5f2c-800b-ae83-5a0b9399cb5c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
